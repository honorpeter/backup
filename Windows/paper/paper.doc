



	基于yolov2算法的深度学习目标识别
摘要：
	我们基于yolov2算法进行目标识别，yolov2是yolo的改进版。yolo是一种
把目标识别问题转化为回归问题的深度学习方法，有别于rcnn系列目标识别算法，也有别于基于DPM的传统目标识别算法。rcnn系列算法 采取proposal+分类的思路，proposal提供位置信息，分类对proposal进行分类。DPM是一种基于 提取HOG特征+使用窗口滑动HOG特征+分类窗口 的目标识别算法。yolo使用卷积神经网络进行图片的特征提取，在输出层回归bounding box的位置和box的类别。yolov2在yolo的基础上，提出了一系列改进的方法，在处理速度不变的情况下，提高了检测的精度。我们主要改进了yolov2的网络结构，去掉一些冗余的中间层，加快识别的速度，精度基本可以保持一致。

介绍
	人类只需要看一眼，便可以立马识别出图像中的物体是什么，并且知道他们在哪里。人类的视力系统识别效率如此的高和快速，可以让我们很快识别出复杂的物体。快速，高效的目标检测算法可以让计算机实时识别出视频中各种物体，如车辆，行人，可以作为了机器人的视觉系统。
	现在目标识别系统，都是基于分类来做的。为了识别目标，需要使用固定大小的窗口滑动整个图片，使用分类模型判断每个窗口所属类别的自信度，DPM目标识别模型便是依据这样的思路。rcnn系列模型先产生很多后选框，分类每个后选框，最后通过预测的张量调整每个后选框的位置来得出最后的结果。
	yolo将目标识别任务作为回归问题来处理，直接根据图像的像素值来预测目标区域的位置以及所属类别的概率。只需要扫描一次图片便可以识别出目标。检测过程如图1，相比较其他目标识别方法，yolo具有以下优点。






			图1： 目标识别过程： 1）将图片调整为448*448， 2） 使用卷积网络提取特征 3）通过模型得出的自信度来识别目标。
	1）检测速度快，可以实时检测目标，在Titan X GPU上可以跑45帧每秒，并且识别效果是其他实时识别的两倍。
	2）滑动窗口和列举后选框都是基于局部信息来进行分类，经常会把背景识别为目标，yolo通过全局图像信息来识别目标，可以减少背景的错误识别率。
	3）yolo泛化能力强，当预测没有训练过的目标时，效果会好些。


yolov2在yolo的基础上，提出了一系列方法改进了，在保持原有的速度的同时，提高了识别精度。主要在一下方面做了改进：
	1）在每个的卷基层后面添加了batch normalization层，来归一化中间数据，使得输入数据，中间数据分布大致相同。通过添加batch normalization层，极大的加快了收敛速度。
	2） 提高了输入图片的分辨率，AlexNet输入图片会被resize到不足256 * 256，这导致分辨率不够高，给检测带来困难。yolo使用分辨率为448*448的图片作为输入。
	3）借鉴了Faster R-CNN中的anchor思想，在卷积特征图上进行滑窗采样，每个中心预测5种不同大小和比例的后选框。由于都是卷积不需要reshape，很好的保留的空间信息，最终特征图的每个特征点和原图的每个cell一一对应。而且用预测相对偏移（offset）取代直接预测坐标简化了问题，方便网络学习。

我们改进了网络结构，去除一些冗余的层。主要将几个卷基层去掉了。







将输入图片调整为448*448大小，图片分割为7×7的网格




摘要  大致写的什么
	贡献点 点一下

2 具体介绍一下
	贡献点 展开
数据集	
3 怎么实现 caffe

4 实验效果
5 总结



参考文献：
压缩的
yolo一二
rcnn系列
dpm
google net
alxnet 
batch normalization
